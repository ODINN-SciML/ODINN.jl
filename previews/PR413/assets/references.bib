
@article{bolibar_universal_2023,
	title = {Universal differential equations for glacier ice flow modelling},
	volume = {16},
	issn = {1991-959X},
	url = {https://gmd.copernicus.org/articles/16/6671/2023/},
	doi = {10.5194/gmd-16-6671-2023},
	abstract = {Geoscientific models are facing increasing challenges to exploit growing datasets coming from remote sensing. Universal differential equations (UDEs), aided by differentiable programming, provide a new scientific modelling paradigm enabling both complex functional inversions to potentially discover new physical laws and data assimilation from heterogeneous and sparse observations. We demonstrate an application of UDEs as a proof of concept to learn the creep component of ice flow, i.e. a nonlinear diffusivity differential equation, of a glacier evolution model. By combining a mechanistic model based on a two-dimensional shallow-ice approximation partial differential equation with an embedded neural network, i.e. a UDE, we can learn parts of an equation as nonlinear functions that then can be translated into mathematical expressions. We implemented this modelling framework as ODINN.jl, a package in the Julia programming language, providing high performance, source-to-source automatic differentiation (AD) and seamless integration with tools and global datasets from the Open Global Glacier Model in Python. We demonstrate this concept for 17 different glaciers around the world, for which we successfully recover a prescribed artificial law describing ice creep variability by solving ∼ 500 000 ordinary differential equations in parallel. Furthermore, we investigate which are the best tools in the scientific machine learning ecosystem in Julia to differentiate and optimize large nonlinear diffusivity UDEs. This study represents a proof of concept for a new modelling framework aiming at discovering empirical laws for large-scale glacier processes, such as the variability in ice creep and basal sliding for ice flow, and new hybrid surface mass balance models.},
	language = {English},
	number = {22},
	urldate = {2025-01-29},
	journal = {Geoscientific Model Development},
	author = {Bolibar, Jordi and Sapienza, Facundo and Maussion, Fabien and Lguensat, Redouane and Wouters, Bert and Pérez, Fernando},
	month = nov,
	year = {2023},
	note = {Publisher: Copernicus GmbH},
	pages = {6671--6687},
	file = {Bolibar et al_2023_Universal differential equations for glacier ice flow modelling.pdf:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/Bolibar et al_2023_Universal differential equations for glacier ice flow modelling2.pdf:application/pdf},
}


@article{rackauckas_universal_2020,
	title = {Universal {Differential} {Equations} for {Scientific} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2001.04385},
	abstract = {In the context of science, the well-known adage "a picture is worth a thousand words" might well be "a model is worth a thousand datasets." Scientific models, such as Newtonian physics or biological gene regulatory networks, are human-driven simplifications of complex phenomena that serve as surrogates for the countless experiments that validated the models. Recently, machine learning has been able to overcome the inaccuracies of approximate modeling by directly learning the entire set of nonlinear interactions from data. However, without any predetermined structure from the scientific basis behind the problem, machine learning approaches are flexible but data-expensive, requiring large databases of homogeneous labeled training data. A central challenge is reconciling data that is at odds with simplified models without requiring "big data". In this work we develop a new methodology, universal differential equations (UDEs), which augments scientific models with machine-learnable structures for scientifically-based learning. We show how UDEs can be utilized to discover previously unknown governing equations, accurately extrapolate beyond the original data, and accelerate model simulation, all in a time and data-efficient manner. This advance is coupled with open-source software that allows for training UDEs which incorporate physical constraints, delayed interactions, implicitly-defined events, and intrinsic stochasticity in the model. Our examples show how a diverse set of computationally-difficult modeling issues across scientific disciplines, from automatically discovering biological mechanisms to accelerating climate simulations by 15,000x, can be handled by training UDEs.},
	urldate = {2020-01-15},
	journal = {arXiv:2001.04385 [cs, math, q-bio, stat]},
	author = {Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.04385},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Dynamical Systems, Mathematics - Numerical Analysis, Quantitative Biology - Quantitative Methods, \_tablet},
	annote = {arXiv: 2001.04385},
	annote = {Comment: 3 figures and 2 supplemental figures, 6 pages},
	annote = {Comment: 3 figures and 2 supplemental figures, 6 pages},
	file = {arXiv.org Snapshot:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/storage/VCT95BZZ/2001.html:text/html;Rackauckas et al_2020_Universal Differential Equations for Scientific Machine Learning.pdf:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/storage/5D5NP372/Rackauckas et al_2020_Universal Differential Equations for Scientific Machine Learning.pdf:application/pdf},
}


@misc{sapienza_differentiable_2024,
	title = {Differentiable {Programming} for {Differential} {Equations}: {A} {Review}},
	copyright = {All rights reserved},
	shorttitle = {Differentiable {Programming} for {Differential} {Equations}},
	url = {http://arxiv.org/abs/2406.09699},
	abstract = {The differentiable programming paradigm is a cornerstone of modern scientific computing. It refers to numerical methods for computing the gradient of a numerical model's output. Many scientific models are based on differential equations, where differentiable programming plays a crucial role in calculating model sensitivities, inverting model parameters, and training hybrid models that combine differential equations with data-driven approaches. Furthermore, recognizing the strong synergies between inverse methods and machine learning offers the opportunity to establish a coherent framework applicable to both fields. Differentiating functions based on the numerical solution of differential equations is non-trivial. Numerous methods based on a wide variety of paradigms have been proposed in the literature, each with pros and cons specific to the type of problem investigated. Here, we provide a comprehensive review of existing techniques to compute derivatives of numerical solutions of differential equations. We first discuss the importance of gradients of solutions of differential equations in a variety of scientific domains. Second, we lay out the mathematical foundations of the various approaches and compare them with each other. Third, we cover the computational considerations and explore the solutions available in modern scientific software. Last but not least, we provide best-practices and recommendations for practitioners. We hope that this work accelerates the fusion of scientific models and data, and fosters a modern approach to scientific modelling.},
	urldate = {2024-09-02},
	publisher = {arXiv},
	author = {Sapienza, Facundo and Bolibar, Jordi and Schäfer, Frank and Groenke, Brian and Pal, Avik and Boussange, Victor and Heimbach, Patrick and Hooker, Giles and Pérez, Fernando and Persson, Per-Olof and Rackauckas, Christopher},
	month = jun,
	year = {2024},
	note = {arXiv:2406.09699 [physics, stat]},
	keywords = {Physics - Computational Physics, Statistics - Machine Learning, Mathematics - Dynamical Systems, Mathematics - Numerical Analysis, 34-04, 49K40, 65D25, 65L09, 65M32, 86A22, 90C31, Computer Science - Numerical Analysis, \_tablet},
	file = {arXiv.org Snapshot:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/storage/QRA8FNAC/2406.html:text/html;arXiv.org Snapshot:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/storage/UERKR85P/2406.html:text/html;Sapienza et al_2024_Differentiable Programming for Differential Equations.pdf:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/storage/G7TESCFH/Sapienza et al_2024_Differentiable Programming for Differential Equations.pdf:application/pdf},
}


@misc{facundo_sapienza_spherical_2025,
	title = {Spherical {Path} {Regression} through {Universal} {Differential} {Equations} with {Applications} to {Paleomagnetism}},
	url = {https://essopenarchive.org/users/887413/articles/1265456-spherical-path-regression-through-universal-differential-equations-with-applications-to-paleomagnetism},
	urldate = {2025-02-07},
	author = {{Facundo Sapienza} and {Leandro Cesar Gallo} and {Jordi Bolibar} and {Fernando Perez} and {Jonathan Taylor}},
	month = feb,
	year = {2025},
	file = {Spherical Path Regression through Universal Differential Equations with Applications to Paleomagnetism:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/storage/QLCHRPV3/1265456-spherical-path-regression-through-universal-differential-equations-with-applications-to.html:text/html},
}


@article{kim_stiff_2021,
	title = {Stiff neural ordinary differential equations},
	volume = {31},
	issn = {1054-1500, 1089-7682},
	url = {https://aip.scitation.org/doi/10.1063/5.0060697},
	doi = {10.1063/5.0060697},
	language = {en},
	number = {9},
	urldate = {2022-02-25},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Kim, Suyong and Ji, Weiqi and Deng, Sili and Ma, Yingbo and Rackauckas, Christopher},
	month = sep,
	year = {2021},
	pages = {093122},
	file = {Versió enviada:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/storage/J3MCWRAP/Kim et al. - 2021 - Stiff neural ordinary differential equations.pdf:application/pdf},
}


@article{sjursen_machine_2025,
	title = {Machine learning improves seasonal mass balance prediction for unmonitored glaciers},
	url = {https://egusphere.copernicus.org/preprints/2025/egusphere-2025-1206/},
	doi = {10.5194/egusphere-2025-1206},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} Glacier evolution models based on temperature-index approaches are commonly used to assess hydrological impacts of glacier changes. However, in large-scale applications, these models lack calibration frameworks that efficiently leverage sparse high-resolution observations, limiting their ability to resolve seasonal mass changes. Machine learning approaches can potentially address this limitation by learning relationships from sparse data that are transferable in space and time, including to unmonitored glaciers. Here, we present the Mass Balance Machine (MBM), a data-driven mass balance model based on the XGBoost architecture, designed to provide accurate and high spatio-temporal resolution regional-scale reconstructions of glacier mass balance. We trained and tested MBM using a dataset of approximately 4000 seasonal and annual point mass balance measurements from 32 glaciers across heterogeneous climate settings in mainland Norway, spanning from 1962 to 2021. To assess the advantage MBM's generalisation capabilities, we compared its predictions on independent test glaciers at various spatio-temporal scales with those of regional-scale simulations from three glacier evolution models. MBM successfully predicted annual and seasonal point mass balance on the test glaciers (RMSE of 0.59\&ndash;1.00 m w.e. and bias of -0.01\&ndash;0.04 m w.e.). On seasonal mass balance, MBM outperformed the other models across spatial scales, reducing RMSE by up to 46 \% and 25 \% on glacier-wide winter and summer mass balance, respectively. Our results demonstrate the capability of machine learning models to generalise across glaciers and climatic settings from relatively sparse mass balance data, highlighting their potential for a wide range of applications.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2025-07-07},
	journal = {EGUsphere},
	author = {Sjursen, Kamilla Hauknes and Bolibar, Jordi and van der Meer, Marijn and Andreassen, Liss Marie and Biesheuvel, Julian Peter and Dunse, Thorben and Huss, Matthias and Maussion, Fabien and Rounce, David R. and Tober, Brandon},
	month = mar,
	year = {2025},
	note = {Publisher: Copernicus GmbH},
	pages = {1--39},
	file = {Sjursen et al_2025_Machine learning improves seasonal mass balance prediction for unmonitored.pdf:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/Sjursen et al_2025_Machine learning improves seasonal mass balance prediction for unmonitored2.pdf:application/pdf},
}


@article{morlighem_inversion_2013,
	title = {Inversion of basal friction in {Antarctica} using exact and incomplete adjoints of a higher-order model},
	volume = {118},
	copyright = {©2013. American Geophysical Union. All Rights Reserved.},
	issn = {2169-9011},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jgrf.20125},
	doi = {10.1002/jgrf.20125},
	abstract = {Basal friction beneath ice sheets remains poorly characterized and yet is a fundamental control on ice mechanics. Here we use a complete map of surface velocity of the Antarctic Ice Sheet to infer the basal friction over the entire continent by combining these observations with a three-dimensional, thermomechanical, higher-order ice sheet numerical model from the Ice Sheet System Model open source software. We demonstrate that inverse methods can be readily applied at the continental scale with appropriate selections of cost function and of scheme of regularization, at a spatial resolution as high as 3 km along the coastline. We compare the convergence of two descent algorithms with the exact and incomplete adjoints to show that the incomplete adjoint is an excellent approximation. The results reveal that the driving stress is almost entirely balanced by the basal shear stress over 80\% of the ice sheet. The basal friction coefficient, which relates basal friction to basal velocity, is, however, significantly heterogeneous: it is low on fast moving ice and high near topographic divides. Areas with low values extend far out into the interior, along glacier and ice stream tributaries, almost to the flanks of topographic divides, suggesting that basal sliding is widespread beneath the Antarctic Ice Sheet.},
	language = {en},
	number = {3},
	urldate = {2025-08-06},
	journal = {Journal of Geophysical Research: Earth Surface},
	author = {Morlighem, M. and Seroussi, H. and Larour, E. and Rignot, E.},
	year = {2013},
	keywords = {basal friction, exact adjoint, incomplete adjoint, inverse method, large-scale modeling},
	pages = {1746--1753},
	file = {Morlighem et al_2013_Inversion of basal friction in Antarctica using exact and incomplete adjoints.pdf:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/Morlighem et al_2013_Inversion of basal friction in Antarctica using exact and incomplete adjoints.pdf:application/pdf;Snapshot:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/storage/XGAER9PW/jgrf.html:text/html},
}


@misc{law_what_2025,
	title = {What is glacier sliding},
	url = {http://arxiv.org/abs/2407.13577},
	doi = {10.48550/arXiv.2407.13577},
	abstract = {Glacier and ice-sheet motion is fundamental to glaciology. However, there is still no clear consensus for the optimal way to describe the sliding component of glacier and ice-sheet dynamics. Typically, sliding is parametrised using a traction coefficient linked to a given theory describing one or a limited set of sliding processes. However, this precludes the possibility of multiple overlapping, spatio-temporally varying sliding modes with inaccuracies resulting in model error propagation as the system evolves away from the conditions under which it was optimised for. Here, we describe glacier sliding as a scale- and setting-dependent 'inner flow' that arises from multiple overlapping sub-processes, including viscous ice deformation and obstacle resistance (or 'form drag'). The corresponding 'outer flow' then accounts for ice deformation that is minimally influenced by bed properties. Following this framework, we suggest that a rough-smooth bed division may be more consequential than a hard-soft one, and that the importance of 'Iken's bound' may be significantly reduced if viscous ice deformation becomes significant in a given region within the inner flow, which may explain the persistent functionality of power-law sliding in large-scale process-agnostic sliding studies over rough topography. Further, reviewing observation-based studies and considering the diversity of sliding processes and settings, we suggest that a simple 'unified' sliding relationship controlled by a single tunable coefficient may not be realistic. However, we show that given reasonable assumptions, sliding relationships should generally fall within a sum of regularised-Coulomb and power-law components, and suggest that a or compound, or power-law relationship with careful consideration of the power value may provide the most flexible way to account for the varied net effect of compound sliding sub-processes.},
	urldate = {2025-04-30},
	publisher = {arXiv},
	author = {Law, Robert and Chandler, David and Born, Andreas},
	month = mar,
	year = {2025},
	note = {arXiv:2407.13577 [physics]},
	keywords = {Physics - Geophysics},
	file = {Law et al_2025_What is glacier sliding.pdf:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/Law et al_2025_What is glacier sliding.pdf:application/pdf;Snapshot:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/storage/DGD8LVKM/2407.html:text/html},
}


@article{gelbrecht_differentiable_2023,
	title = {Differentiable programming for {Earth} system modeling},
	volume = {16},
	issn = {1991-959X},
	url = {https://gmd.copernicus.org/articles/16/3123/2023/},
	doi = {10.5194/gmd-16-3123-2023},
	abstract = {Earth system models (ESMs) are the primary tools for investigating future Earth system states at timescales from decades to centuries, especially in response to anthropogenic greenhouse gas release. State-of-the-art ESMs can reproduce the observational global mean temperature anomalies of the last 150 years. Nevertheless, ESMs need further improvements, most importantly regarding (i) the large spread in their estimates of climate sensitivity, i.e., the temperature response to increases in atmospheric greenhouse gases; (ii) the modeled spatial patterns of key variables such as temperature and precipitation; (iii) their representation of extreme weather events; and (iv) their representation of multistable Earth system components and the ability to predict associated abrupt transitions. Here, we argue that making ESMs automatically differentiable has a huge potential to advance ESMs, especially with respect to these key shortcomings. First, automatic differentiability would allow objective calibration of ESMs, i.e., the selection of optimal values with respect to a cost function for a large number of free parameters, which are currently tuned mostly manually. Second, recent advances in machine learning (ML) and in the number, accuracy, and resolution of observational data promise to be helpful with at least some of the above aspects because ML may be used to incorporate additional information from observations into ESMs. Automatic differentiability is an essential ingredient in the construction of such hybrid models, combining process-based ESMs with ML components. We document recent work showcasing the potential of automatic differentiation for a new generation of substantially improved, data-informed ESMs.},
	language = {English},
	number = {11},
	urldate = {2025-03-27},
	journal = {Geoscientific Model Development},
	author = {Gelbrecht, Maximilian and White, Alistair and Bathiany, Sebastian and Boers, Niklas},
	month = jun,
	year = {2023},
	note = {Publisher: Copernicus GmbH},
	pages = {3123--3135},
	file = {Gelbrecht et al_2023_Differentiable programming for Earth system modeling.pdf:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/Gelbrecht et al_2023_Differentiable programming for Earth system modeling.pdf:application/pdf},
}

@article{wang_deep_2025,
	title = {Deep learning the flow law of {Antarctic} ice shelves},
	volume = {387},
	url = {https://www-science-org.insu.bib.cnrs.fr/doi/10.1126/science.adp3300},
	doi = {10.1126/science.adp3300},
	abstract = {Antarctic ice shelves buttress the grounded ice sheet, mitigating global sea level rise. However, fundamental mechanical properties, such as the ice flow law and viscosity structure, remain under debate. In this work, by leveraging remote-sensing data and physics-informed deep learning, we provide evidence over several ice shelves that the flow law follows a grain size–sensitive composite rheology in the compression zone. In the extension zone, we found that ice exhibits anisotropic properties. We constructed ice shelf–wide anisotropic viscosity maps that capture the suture zones, which inhibit rift propagation. The inferred stress exponent near the grounding zone dictates the grounding-line ice flux and grounding line stability, whereas the inferred viscosity maps inform the prediction of rifts. Both are essential for predicting the future mass loss of the Antarctic Ice Sheet.},
	number = {6739},
	urldate = {2025-03-17},
	journal = {Science},
	author = {Wang, Yongji and Lai, Ching-Yao and Prior, David J. and Cowen-Breen, Charlie},
	month = mar,
	year = {2025},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1219--1224},
	file = {Wang et al_2025_Deep learning the flow law of Antarctic ice shelves.pdf:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/Wang et al_2025_Deep learning the flow law of Antarctic ice shelves.pdf:application/pdf},
}


@misc{cranmer_interpretable_2023,
	title = {Interpretable {Machine} {Learning} for {Science} with {PySR} and {SymbolicRegression}.jl},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2305.01582},
	doi = {10.48550/ARXIV.2305.01582},
	abstract = {PySR is an open-source library for practical symbolic regression, a type of machine learning which aims to discover human-interpretable symbolic models. PySR was developed to democratize and popularize symbolic regression for the sciences, and is built on a high-performance distributed back-end, a flexible search algorithm, and interfaces with several deep learning packages. PySR's internal search algorithm is a multi-population evolutionary algorithm, which consists of a unique evolve-simplify-optimize loop, designed for optimization of unknown scalar constants in newly-discovered empirical expressions. PySR's backend is the extremely optimized Julia library SymbolicRegression.jl, which can be used directly from Julia. It is capable of fusing user-defined operators into SIMD kernels at runtime, performing automatic differentiation, and distributing populations of expressions to thousands of cores across a cluster. In describing this software, we also introduce a new benchmark, "EmpiricalBench," to quantify the applicability of symbolic regression algorithms in science. This benchmark measures recovery of historical empirical equations from original and synthetic datasets.},
	urldate = {2025-01-15},
	publisher = {arXiv},
	author = {Cranmer, Miles},
	year = {2023},
	note = {Version Number: 3},
	keywords = {FOS: Physical sciences, FOS: Computer and information sciences, Machine Learning (cs.LG), Symbolic Computation (cs.SC), Data Analysis, Statistics and Probability (physics.data-an), Instrumentation and Methods for Astrophysics (astro-ph.IM), Neural and Evolutionary Computing (cs.NE)},
	annote = {Other
24 pages, 5 figures, 3 tables. Feedback welcome. Paper source found at https://github.com/MilesCranmer/pysr\_paper ; PySR at https://github.com/MilesCranmer/PySR ; SymbolicRegression.jl at https://github.com/MilesCranmer/SymbolicRegression.jl},
}


@misc{kidger_neural_2022,
	title = {On {Neural} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2202.02435},
	doi = {10.48550/arXiv.2202.02435},
	abstract = {The conjoining of dynamical systems and deep learning has become a topic of great interest. In particular, neural differential equations (NDEs) demonstrate that neural networks and differential equation are two sides of the same coin. Traditional parameterised differential equations are a special case. Many popular neural network architectures, such as residual networks and recurrent networks, are discretisations. NDEs are suitable for tackling generative problems, dynamical systems, and time series (particularly in physics, finance, ...) and are thus of interest to both modern machine learning and traditional mathematical modelling. NDEs offer high-capacity function approximation, strong priors on model space, the ability to handle irregular data, memory efficiency, and a wealth of available theory on both sides. This doctoral thesis provides an in-depth survey of the field. Topics include: neural ordinary differential equations (e.g. for hybrid neural/mechanistic modelling of physical systems); neural controlled differential equations (e.g. for learning functions of irregular time series); and neural stochastic differential equations (e.g. to produce generative models capable of representing complex stochastic dynamics, or sampling from complex high-dimensional distributions). Further topics include: numerical methods for NDEs (e.g. reversible differential equations solvers, backpropagation through differential equations, Brownian reconstruction); symbolic regression for dynamical systems (e.g. via regularised evolution); and deep implicit models (e.g. deep equilibrium models, differentiable optimisation). We anticipate this thesis will be of interest to anyone interested in the marriage of deep learning with dynamical systems, and hope it will provide a useful reference for the current state of the art.},
	language = {en},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Kidger, Patrick},
	month = feb,
	year = {2022},
	note = {arXiv:2202.02435 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Dynamical Systems, Mathematics - Numerical Analysis, Mathematics - Classical Analysis and ODEs, Computer Science - Numerical Analysis, \_tablet},
	annote = {Comment: Doctoral thesis, Mathematical Institute, University of Oxford. 231 pages},
	file = {Kidger_2022_On Neural Differential Equations.pdf:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/storage/348MZKU9/Kidger_2022_On Neural Differential Equations.pdf:application/pdf},
}


@book{cuffey_physics_2010,
	title = {The {Physics} of {Glaciers}},
	isbn = {978-0-08-091912-6},
	url = {https://books.google.fr/books?id=Jca2v1u1EKEC},
	publisher = {Elsevier Science},
	author = {Cuffey, K.M. and Paterson, W.S.B.},
	year = {2010},
}


@article{zekollari_ice_dynamical_2022,
	title = {Ice-{Dynamical} {Glacier} {Evolution} {Modeling}—{A} {Review}},
	volume = {60},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2021RG000754},
	abstract = {Abstract Glaciers play a crucial role in the Earth System: they are important water suppliers to lower-lying areas during hot and dry periods, and they are major contributors to the observed present-day sea-level rise. Glaciers can also act as a source of natural hazards and have a major touristic value. Given their societal importance, there is large scientific interest in better understanding and accurately simulating the temporal evolution of glaciers, both in the past and in the future. Here, we give an overview of the state of the art of simulating the evolution of individual glaciers over decadal to centennial time scales with ice-dynamical models. We hereby highlight recent advances in the field and emphasize how these go hand-in-hand with an increasing availability of on-site and remotely sensed observations. We also focus on the gap between simplified studies that use parameterizations, typically used for regional and global projections, and detailed assessments for individual glaciers, and explain how recent advances now allow including ice dynamics when modeling glaciers at larger spatial scales. Finally, we provide concrete recommendations concerning the steps and factors to be considered when modeling the evolution of glaciers. We suggest paying particular attention to the model initialization, analyzing how related uncertainties in model input influence the modeled glacier evolution and strongly recommend evaluating the simulated glacier evolution against independent data.},
	number = {2},
	journal = {Reviews of Geophysics},
	author = {Zekollari, H. and Huss, M. and Farinotti, D. and Lhermitte, S.},
	year = {2022},
	keywords = {dynamics, evolution, glacier, ice, mass balance, modeling},
	pages = {e2021RG000754},
	annote = {e2021RG000754 2021RG000754},
}


@article{gimbert_existing_2021,
	title = {Do {Existing} {Theories} {Explain} {Seasonal} to {Multi}-{Decadal} {Changes} in {Glacier} {Basal} {Sliding} {Speed}?},
	volume = {48},
	number = {15},
	journal = {Geophysical Research Letters},
	author = {Gimbert, F and Gilbert, A and Gagliardini, O and Vincent, C and Moreau, L},
	year = {2021},
	note = {Publisher: Wiley Online Library},
	pages = {e2021GL092858},
}


@article{thuerey_physics-based_2021,
	title = {Physics-based {Deep} {Learning}},
	url = {http://arxiv.org/abs/2109.05237},
	abstract = {This digital book contains a practical and comprehensive introduction of everything related to deep learning in the context of physical simulations. As much as possible, all topics come with hands-on code examples in the form of Jupyter notebooks to quickly get started. Beyond standard supervised learning from data, we'll look at physical loss constraints, more tightly coupled learning algorithms with differentiable simulations, as well as reinforcement learning and uncertainty modeling. We live in exciting times: these methods have a huge potential to fundamentally change what computer simulations can achieve.},
	urldate = {2022-02-25},
	journal = {arXiv:2109.05237 [physics]},
	author = {Thuerey, Nils and Holl, Philipp and Mueller, Maximilian and Schnell, Patrick and Trost, Felix and Um, Kiwon},
	month = dec,
	year = {2021},
	note = {arXiv: 2109.05237},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Computer Science - Artificial Intelligence, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Physics - Data Analysis, Statistics and Probability},
	annote = {arXiv: 1710.11431},
	annote = {arXiv: 2109.05237},
	annote = {Comment: Online version at: https://www.physicsbaseddeeplearning.org/},
	annote = {Comment: Online version at: https://www.physicsbaseddeeplearning.org/},
	annote = {Comment: submitted to ACM SIGKDD 2018},
	file = {arXiv Fulltext PDF:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/storage/GMWFFUPM/Thuerey et al. - 2021 - Physics-based Deep Learning.pdf:application/pdf;arXiv.org Snapshot:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/storage/NXEADTQ5/2109.html:text/html},
}


@article{welty_worldwide_2020,
	title = {Worldwide version-controlled database of glacier thickness observations},
	volume = {12},
	issn = {1866-3508},
	url = {https://essd.copernicus.org/articles/12/3039/2020/},
	doi = {10.5194/essd-12-3039-2020},
	abstract = {Although worldwide inventories of glacier area have been coordinated internationally for several decades, a similar effort for glacier ice thicknesses was only initiated in 2013. Here, we present the third version of the Glacier Thickness Database (GlaThiDa v3), which includes 3\&thinsp;854\&thinsp;279 thickness measurements distributed over roughly 3000 glaciers worldwide. Overall, 14\&thinsp;\% of global glacier area is now within 1\&thinsp;km of a thickness measurement (located on the same glacier) – a significant improvement over GlaThiDa v2, which covered only 6\&thinsp;\% of global glacier area and only 1100 glaciers. Improvements in measurement coverage increase the robustness of numerical interpolations and model extrapolations, resulting in better estimates of regional to global glacier volumes and their potential contributions to sea-level rise.

 In this paper, we summarize the sources and compilation of glacier thickness data and the spatial and temporal coverage of the resulting database. In addition, we detail our use of open-source metadata formats and software tools to describe the data, validate the data format and content against this metadata description, and track changes to the data following modern data management best practices. Archived versions of GlaThiDa are available from the World Glacier Monitoring Service (e.g., v3.1.0, from which this paper was generated: https://doi.org/10.5904/wgms-glathida-2020-10; GlaThiDa Consortium, 2020), while the development version is available on GitLab (https://gitlab.com/wgms/glathida, last access: 9 November 2020).},
	language = {English},
	number = {4},
	urldate = {2025-08-12},
	journal = {Earth System Science Data},
	author = {Welty, Ethan and Zemp, Michael and Navarro, Francisco and Huss, Matthias and Fürst, Johannes J. and Gärtner-Roer, Isabelle and Landmann, Johannes and Machguth, Horst and Naegeli, Kathrin and Andreassen, Liss M. and Farinotti, Daniel and Li, Huilin and GlaThiDa Contributors},
	month = nov,
	year = {2020},
	note = {Publisher: Copernicus GmbH},
	pages = {3039--3055},
	file = {Welty et al_2020_Worldwide version-controlled database of glacier thickness observations.pdf:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/Welty et al_2020_Worldwide version-controlled database of glacier thickness observations.pdf:application/pdf},
}


@article{millan_ice_2022,
	title = {Ice velocity and thickness of the world’s glaciers},
	volume = {15},
	issn = {1752-0894, 1752-0908},
	url = {https://www.nature.com/articles/s41561-021-00885-z},
	doi = {10.1038/s41561-021-00885-z},
	language = {en},
	number = {2},
	urldate = {2022-02-25},
	journal = {Nature Geoscience},
	author = {Millan, Romain and Mouginot, Jérémie and Rabatel, Antoine and Morlighem, Mathieu},
	month = feb,
	year = {2022},
	pages = {124--129},
}

@article{rabatel_satellite-derived_2023,
	title = {Satellite-{Derived} {Annual} {Glacier} {Surface} {Flow} {Velocity} {Products} for the {European} {Alps}, 2015–2021},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2306-5729},
	url = {https://www.mdpi.com/2306-5729/8/4/66},
	doi = {10.3390/data8040066},
	abstract = {Documenting glacier surface flow velocity from a longer-term perspective is highly relevant to evaluate the past and current state of glaciers worldwide. For this purpose, satellite data are widely used to obtain region-wide coverage of glacier velocity data. Well-established image correlation methods allow for the automated measurement of glacier surface displacements from satellite data (optical and radar) acquired at different dates. Although computationally expensive, image correlation is nowadays relatively simple to implement and allows two-dimensional displacement measurements. Here, we present a data set of annual glacier surface flow velocity maps at the European Alps scale, covering the period 2015–2021 at a 50 m × 50 m resolution. This data set has been quantified by applying the normalized cross-correlation approach on Sentinel-2 optical data. Parameters of the cross-correlation method (e.g., window size, sampling resolution) have been optimized, and the results have been validated by comparing them with in situ data on monitored glaciers showing an RMSE of 10 m/yr. These data can be used to evaluate glacier dynamics and its spatial and temporal evolution (e.g., quantify mass fluxes or calving) or can be used as an input for model calibration/validation or for the early detection of regional hazards associated with glacier destabilization.},
	language = {en},
	number = {4},
	urldate = {2025-01-28},
	journal = {Data},
	author = {Rabatel, Antoine and Ducasse, Etienne and Millan, Romain and Mouginot, Jérémie},
	month = apr,
	year = {2023},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {mountain glaciers, European Alps, normalized cross correlation, optical remote sensing, Sentinel-2, surface flow velocity},
	pages = {66},
	file = {Rabatel et al_2023_Satellite-Derived Annual Glacier Surface Flow Velocity Products for the.pdf:/Users/Bolib001/Desktop/Jordi/Bibliography/Zotero/Rabatel et al_2023_Satellite-Derived Annual Glacier Surface Flow Velocity Products for the.pdf:application/pdf},
}


