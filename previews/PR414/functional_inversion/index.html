<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Functional inversion · ODINN.jl</title><meta name="title" content="Functional inversion · ODINN.jl"/><meta property="og:title" content="Functional inversion · ODINN.jl"/><meta property="twitter:title" content="Functional inversion · ODINN.jl"/><meta name="description" content="Documentation for ODINN.jl."/><meta property="og:description" content="Documentation for ODINN.jl."/><meta property="twitter:description" content="Documentation for ODINN.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ODINN.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">ODINN.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../quick_start/">Quick start</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../forward_simulation/">Forward simulation</a></li><li class="is-active"><a class="tocitem" href>Functional inversion</a><ul class="internal"><li><a class="tocitem" href="#Running-the-whole-code"><span>Running the whole code</span></a></li><li><a class="tocitem" href="#Step-by-step-explanation-of-the-tutorial"><span>Step-by-step explanation of the tutorial</span></a></li></ul></li><li><a class="tocitem" href="../laws/">Laws</a></li><li><a class="tocitem" href="../vjp_laws/">VJP law customization</a></li><li><a class="tocitem" href="../input_laws/">Laws inputs</a></li></ul></li><li><span class="tocitem">How to use ODINN</span><ul><li><a class="tocitem" href="../parameters/">Parameters</a></li><li><a class="tocitem" href="../glaciers/">Glaciers</a></li><li><a class="tocitem" href="../models/">Models</a></li><li><a class="tocitem" href="../results_plotting/">Results and plotting</a></li><li><a class="tocitem" href="../api/">API</a></li></ul></li><li><span class="tocitem">Inversions</span><ul><li><a class="tocitem" href="../inversions/">Inversion types</a></li><li><a class="tocitem" href="../optimization/">Optimization</a></li><li><a class="tocitem" href="../sensitivity/">Sensitivity analysis</a></li></ul></li><li><span class="tocitem">Community</span><ul><li><a class="tocitem" href="../contribute/">How to contribute</a></li><li><a class="tocitem" href="../code_of_conduct/">Code of conduct</a></li></ul></li><li><a class="tocitem" href="../changes_plans/">Ongoing changes and future plans</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Functional inversion</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Functional inversion</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ODINN-SciML/ODINN.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ODINN-SciML/ODINN.jl/blob/main/docs/src/functional_inversion.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Functional-inversion-tutorial"><a class="docs-heading-anchor" href="#Functional-inversion-tutorial">Functional inversion tutorial</a><a id="Functional-inversion-tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#Functional-inversion-tutorial" title="Permalink"></a></h1><p>This tutorial provides a simple example on how to perform a functional inversion using Universal Differential Equations (UDEs) in ODINN.jl. For this, we will generate a synthetic dataset using a forward simulation, and then we will use this dataset to perform the functional inversion. The goal of this functional inversion will be to learn a synthetic law that maps <code>A</code>, i.e. the ice rigidity, to long-term changes in atmospheric surface temperature.</p><p>For more details on the functional inversion concept, please refer to the <a href="../inversions/#Functional-inversions">Functional Inversion section in the Inversion types page</a>.</p><h2 id="Running-the-whole-code"><a class="docs-heading-anchor" href="#Running-the-whole-code">Running the whole code</a><a id="Running-the-whole-code-1"></a><a class="docs-heading-anchor-permalink" href="#Running-the-whole-code" title="Permalink"></a></h2><pre><code class="language-julia hljs">using ODINN

# Define the working directory
working_dir = joinpath(ODINN.root_dir, &quot;demos&quot;)

## We fetch the paths with the files for the available glaciers on disk
rgi_paths = get_rgi_paths()

# Ensure the working directory exists
mkpath(working_dir)

# Define which glacier RGI IDs we want to work with
rgi_ids = [&quot;RGI60-11.03638&quot;, &quot;RGI60-11.01450&quot;, &quot;RGI60-11.02346&quot;, &quot;RGI60-07.00065&quot;]
# Define the time step for the simulation output and for the adjoint calculation. In this case, a month.
δt = 1/12

params = Parameters(
    simulation = SimulationParameters(
        working_dir=working_dir,
        use_MB=false,
        use_velocities=true,
        tspan=(2010.0, 2015.0),
        multiprocessing=true,
        workers=4,
        test_mode=false,
        rgi_paths=rgi_paths,
        gridScalingFactor=4), # Downscale the glacier grid to speed-up this example
    hyper = Hyperparameters(
        batch_size=length(rgi_ids), # We set batch size equals all datasize so we test gradient
        epochs=[15,10],
        optimizer=[ODINN.ADAM(0.01), ODINN.LBFGS(linesearch = ODINN.LineSearches.BackTracking(iterations = 5))]),
    physical = PhysicalParameters(
        minA = 8e-21,
        maxA = 8e-17),
    UDE = UDEparameters(
        optim_autoAD=ODINN.NoAD(),
        grad=ContinuousAdjoint(),
        optimization_method=&quot;AD+AD&quot;,
        empirical_loss_function = LossH() # Loss function based on ice thickness
    ),
    solver = Huginn.SolverParameters(
        step=δt,
        progress=true)
)

# We define a synthetic law to generate the synthetic dataset. For this, we use some tabular data from Cuffey and Paterson (2010).
A_law = CuffeyPaterson()

model = Model(
    iceflow = SIA2Dmodel(params; A=A_law),
    mass_balance = TImodel1(params; DDF=6.0/1000.0, acc_factor=1.2/1000.0),
)

# We initialize the glaciers with all the necessary data
glaciers = initialize_glaciers(rgi_ids, params)

# Time snapshots for transient inversion
tstops = collect(2010:δt:2015)

# We generate the synthetic dataset using the forward simulation. This will generate a dataset with the ice thickness and surface velocities for each glacier at each time step. The dataset will be used to train the machine learning model.
glaciers = generate_ground_truth(glaciers, params, model, tstops)

## After this forward simulation, we restart the iceflow model to be ready for the inversions
nn_model = NeuralNetwork(params)
A_law = LawA(nn_model, params)
model = Model(
    iceflow = SIA2Dmodel(params; A=A_law),
    mass_balance = TImodel1(params; DDF=6.0/1000.0, acc_factor=1.2/1000.0),
    regressors = (; A=nn_model)
)

# We specify the type of simulation we want to perform
functional_inversion = Inversion(model, glaciers, params)

# And finally, we just run the simulation
run!(functional_inversion)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">[ Info: Filtering out these glaciers from RGI ID list: Any[]
      From worker 3:	Getting raw climate data for: RGI60-07.00065
[ Info: Running forward in-place PDE ice flow model
      From worker 3:	Processing glacier RGI60-11.03638 for PDE forward simulation
      From worker 4:	Processing glacier RGI60-11.01450 for PDE forward simulation
      From worker 2:	Processing glacier RGI60-11.02346 for PDE forward simulation
      From worker 4:	Processing glacier RGI60-07.00065 for PDE forward simulation
Progress:  50%|████████████████████▌                    |  ETA: 0:00:03Progress:  75%|██████████████████████████████▊          |  ETA: 0:00:01Progress: 100%|█████████████████████████████████████████| Time: 0:00:03
Training UDE...

[ Info: Training with ADAM optimizer
[ Info: Training with custom ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP} method
Iteration: [    1 /    25]     Loss:7.90137e+01
Iteration: [    2 /    25]     Loss:6.52403e+01     Improvement: -17.43 %
Iteration: [    3 /    25]     Loss:5.40509e+01     Improvement: -17.15 %
Iteration: [    4 /    25]     Loss:4.57279e+01     Improvement: -15.40 %
Iteration: [    5 /    25]     Loss:3.89663e+01     Improvement: -14.79 %
Iteration: [    6 /    25]     Loss:3.35554e+01     Improvement: -13.89 %
Iteration: [    7 /    25]     Loss:2.91507e+01     Improvement: -13.13 %
Iteration: [    8 /    25]     Loss:2.55161e+01     Improvement: -12.47 %
Iteration: [    9 /    25]     Loss:2.21683e+01     Improvement: -13.12 %
Iteration: [   10 /    25]     Loss:1.99518e+01     Improvement: -10.00 %
Iteration: [   11 /    25]     Loss:1.75260e+01     Improvement: -12.16 %
Iteration: [   12 /    25]     Loss:1.59671e+01     Improvement: -8.89 %
Iteration: [   13 /    25]     Loss:1.44823e+01     Improvement: -9.30 %
Iteration: [   14 /    25]     Loss:1.31806e+01     Improvement: -8.99 %
Iteration: [   15 /    25]     Loss:1.20103e+01     Improvement: -8.88 %
Iteration: [   16 /    25]     Loss:1.20103e+01     Improvement: 0.00 %
[ Info: Training with BFGS optimizer
[ Info: Training with custom ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP} method
Iteration: [   17 /    25]     Loss:1.20103e+01     Improvement: 0.00 %
Iteration: [   18 /    25]     Loss:1.08576e+01     Improvement: -9.60 %</code></pre><h2 id="Step-by-step-explanation-of-the-tutorial"><a class="docs-heading-anchor" href="#Step-by-step-explanation-of-the-tutorial">Step-by-step explanation of the tutorial</a><a id="Step-by-step-explanation-of-the-tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#Step-by-step-explanation-of-the-tutorial" title="Permalink"></a></h2><p>Here we will cover in detail each one of the steps that lead us to run the <code>Inversion</code> from the previous example. The goal of this simple example is to learn a mapping of a law for <code>A</code>, the creep coefficient of ice. Mathematically, we make <code>A</code> depends on the long term air temperature <code>T</code> through a neural network <code>A=NN(T, θ)</code> and we optimize <code>θ</code> so that the generated solution matches some ice thickness reference. This reference is generated using the relation of the book from Cuffey and Paterson (2010).</p><h3 id="Step-1:-Parameter-and-glacier-initialization"><a class="docs-heading-anchor" href="#Step-1:-Parameter-and-glacier-initialization">Step 1: Parameter and glacier initialization</a><a id="Step-1:-Parameter-and-glacier-initialization-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1:-Parameter-and-glacier-initialization" title="Permalink"></a></h3><p>First we need to specify a list of RGI IDs of the glacier we want to work with. Specifying an RGI region is also possible. From these RGI IDs, we will look for the necessary files inside the workspace.</p><pre><code class="language-julia hljs">rgi_ids = [&quot;RGI60-11.03638&quot;, &quot;RGI60-11.01450&quot;, &quot;RGI60-11.02346&quot;, &quot;RGI60-07.00065&quot;]
rgi_paths = get_rgi_paths()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Dict{String, String} with 56 entries:
  &quot;RGI60-11.00897&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.00/RGI60-11.00897&quot;
  &quot;RGI60-08.00213&quot; =&gt; &quot;per_glacier/RGI60-08/RGI60-08.00/RGI60-08.00213&quot;
  &quot;RGI60-08.00147&quot; =&gt; &quot;per_glacier/RGI60-08/RGI60-08.00/RGI60-08.00147&quot;
  &quot;RGI60-11.01270&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.01/RGI60-11.01270&quot;
  &quot;RGI60-11.03646&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.03/RGI60-11.03646&quot;
  &quot;RGI60-11.03232&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.03/RGI60-11.03232&quot;
  &quot;RGI60-01.22174&quot; =&gt; &quot;per_glacier/RGI60-01/RGI60-01.22/RGI60-01.22174&quot;
  &quot;RGI60-07.00274&quot; =&gt; &quot;per_glacier/RGI60-07/RGI60-07.00/RGI60-07.00274&quot;
  &quot;RGI60-03.04207&quot; =&gt; &quot;per_glacier/RGI60-03/RGI60-03.04/RGI60-03.04207&quot;
  &quot;RGI60-04.04351&quot; =&gt; &quot;per_glacier/RGI60-04/RGI60-04.04/RGI60-04.04351&quot;
  &quot;RGI60-07.00065&quot; =&gt; &quot;per_glacier/RGI60-07/RGI60-07.00/RGI60-07.00065&quot;
  &quot;RGI60-11.02346&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.02/RGI60-11.02346&quot;
  &quot;RGI60-01.00570&quot; =&gt; &quot;per_glacier/RGI60-01/RGI60-01.00/RGI60-01.00570&quot;
  &quot;RGI60-11.01238&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.01/RGI60-11.01238&quot;
  &quot;RGI60-11.03005&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.03/RGI60-11.03005&quot;
  &quot;RGI60-08.00087&quot; =&gt; &quot;per_glacier/RGI60-08/RGI60-08.00/RGI60-08.00087&quot;
  &quot;RGI60-11.00787&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.00/RGI60-11.00787&quot;
  &quot;RGI60-08.00203&quot; =&gt; &quot;per_glacier/RGI60-08/RGI60-08.00/RGI60-08.00203&quot;
  &quot;RGI60-07.01193&quot; =&gt; &quot;per_glacier/RGI60-07/RGI60-07.01/RGI60-07.01193&quot;
  ⋮                =&gt; ⋮</code></pre><p>Define the time step for the simulation output and for the adjoint calculation. In this case, a month.</p><pre><code class="language-julia hljs">δt = 1/12</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.08333333333333333</code></pre><p>Then we need to define the parameters of the simulation we want to perform. The arguments are very similar to the ones used in the forward simulation tutorial and for a complete explanation, the reader should refer to this tutorial. The main difference with the forward simulation tutorial here is that we need to specify the parameters for the functional inversion through the <code>Hyperparameters</code> and the <code>UDEparameters</code>. The <code>Hyperparameters</code> structure contains information about the optimization algorithm. The <code>UDEparameters</code> define how the Universal Differential Equation (UDE) is solved and how its gradient is computed.</p><pre><code class="language-julia hljs">params = Parameters(
    simulation = SimulationParameters(
        working_dir=working_dir,
        use_MB=false,
        use_velocities=true,
        tspan=(2010.0, 2015.0),
        multiprocessing=true,
        workers=4,
        test_mode=false,
        rgi_paths=rgi_paths,
        gridScalingFactor=4), # Downscale the glacier grid to speed-up this example
    hyper = Hyperparameters(
        batch_size=length(rgi_ids), # We set batch size equals all datasize so we test gradient
        epochs=[15,10],
        optimizer=[ODINN.ADAM(0.01), ODINN.LBFGS(linesearch = ODINN.LineSearches.BackTracking(iterations = 5))]),
    physical = PhysicalParameters(
        minA = 8e-21,
        maxA = 8e-17),
    UDE = UDEparameters(
        optim_autoAD=ODINN.NoAD(),
        grad=ContinuousAdjoint(),
        optimization_method=&quot;AD+AD&quot;,
        target = :A),
    solver = Huginn.SolverParameters(
        step=δt,
        progress=true)
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Sleipnir.Parameters{PhysicalParameters{Float64}, SimulationParameters{Int64, Float64, MeanDateVelocityMapping}, Hyperparameters{Float64, Int64}, SolverParameters{Float64, Int64}, UDEparameters{ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP}}, InversionParameters{Float64}}(PhysicalParameters{Float64}(900.0, 9.81, 1.0e-10, 1.0, 8.0e-17, 8.0e-21, 8.0e-17, 8.5e-20, 1.0, -25.0, 5.0e-18), SimulationParameters{Int64, Float64, MeanDateVelocityMapping}(false, true, true, true, 1.0, false, false, (2010.0, 2015.0), 0.08333333333333333, true, 4, &quot;/home/runner/work/ODINN.jl/ODINN.jl/demos&quot;, false, Dict(&quot;RGI60-11.00897&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.00/RGI60-11.00897&quot;, &quot;RGI60-08.00213&quot; =&gt; &quot;per_glacier/RGI60-08/RGI60-08.00/RGI60-08.00213&quot;, &quot;RGI60-08.00147&quot; =&gt; &quot;per_glacier/RGI60-08/RGI60-08.00/RGI60-08.00147&quot;, &quot;RGI60-11.01270&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.01/RGI60-11.01270&quot;, &quot;RGI60-11.03646&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.03/RGI60-11.03646&quot;, &quot;RGI60-11.03232&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.03/RGI60-11.03232&quot;, &quot;RGI60-01.22174&quot; =&gt; &quot;per_glacier/RGI60-01/RGI60-01.22/RGI60-01.22174&quot;, &quot;RGI60-07.00274&quot; =&gt; &quot;per_glacier/RGI60-07/RGI60-07.00/RGI60-07.00274&quot;, &quot;RGI60-03.04207&quot; =&gt; &quot;per_glacier/RGI60-03/RGI60-03.04/RGI60-03.04207&quot;, &quot;RGI60-04.04351&quot; =&gt; &quot;per_glacier/RGI60-04/RGI60-04.04/RGI60-04.04351&quot;…), &quot;Farinotti19&quot;, MeanDateVelocityMapping(:nearest), 4), Hyperparameters{Float64, Int64}(1, 1, Float64[], Any[Optimisers.Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), Optim.LBFGS{Nothing, LineSearches.InitialStatic{Float64}, LineSearches.BackTracking{Float64, Int64}, Returns{Nothing}}(10, LineSearches.InitialStatic{Float64}
  alpha: Float64 1.0
  scaled: Bool false
, LineSearches.BackTracking{Float64, Int64}
  c_1: Float64 0.0001
  ρ_hi: Float64 0.5
  ρ_lo: Float64 0.1
  iterations: Int64 5
  order: Int64 3
  maxstep: Float64 Inf
  cache: Nothing nothing
, nothing, Returns{Nothing}(nothing), Optim.Flat(), true)], 0.0, [15, 10], 4), SolverParameters{Float64, Int64}(OrdinaryDiffEqLowStorageRK.RDPK3Sp35{typeof(OrdinaryDiffEqCore.trivial_limiter!), typeof(OrdinaryDiffEqCore.trivial_limiter!), Static.False}(OrdinaryDiffEqCore.trivial_limiter!, OrdinaryDiffEqCore.trivial_limiter!, static(false)), 1.0e-12, 0.08333333333333333, Float64[], false, true, 10, 100000), UDEparameters{ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP}}(SciMLSensitivity.GaussAdjoint{0, true, Val{:central}, SciMLSensitivity.EnzymeVJP}(SciMLSensitivity.EnzymeVJP(0), false), SciMLBase.NoAD(), ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP}(DiscreteVJP{ADTypes.AutoMooncake{Nothing}}(ADTypes.AutoMooncake()), OrdinaryDiffEqLowStorageRK.RDPK3Sp35{typeof(OrdinaryDiffEqCore.trivial_limiter!), typeof(OrdinaryDiffEqCore.trivial_limiter!), Static.False}(OrdinaryDiffEqCore.trivial_limiter!, OrdinaryDiffEqCore.trivial_limiter!, static(false)), 1.0e-8, 1.0e-8, 0.08333333333333333, :Linear, 200, EnzymeVJP()), &quot;AD+AD&quot;, MultiLoss{Tuple{LossH{L2Sum{Int64}}}, Vector{Float64}}((LossH{L2Sum{Int64}}(L2Sum{Int64}(3)),), [1.0]), :A, :identity), InversionParameters{Float64}([1.0], [0.0], [Inf], [1, 1], 0.001, 0.001, Optim.BFGS{LineSearches.InitialStatic{Float64}, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}, Nothing, Nothing, Optim.Flat}(LineSearches.InitialStatic{Float64}
  alpha: Float64 1.0
  scaled: Bool false
, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}
  delta: Float64 0.1
  sigma: Float64 0.9
  alphamax: Float64 Inf
  rho: Float64 5.0
  epsilon: Float64 1.0e-6
  gamma: Float64 0.66
  linesearchmax: Int64 50
  psi3: Float64 0.1
  display: Int64 0
  mayterminate: Base.RefValue{Bool}
  cache: Nothing nothing
  check_flatness: Bool false
, nothing, nothing, Optim.Flat())))</code></pre><p>Then, we initialize those glaciers based on those RGI IDs and the parameters we previously specified.</p><pre><code class="language-julia hljs">glaciers = initialize_glaciers(rgi_ids, params)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Glacier2D} distributed over regions 07 (x1), 11 (x3)
RGI60-11.03638 RGI60-11.01450 RGI60-11.02346 RGI60-07.00065
</code></pre><h3 id="Step-2:-Defining-a-forward-simulation-as-a-synthetic-ground-truth"><a class="docs-heading-anchor" href="#Step-2:-Defining-a-forward-simulation-as-a-synthetic-ground-truth">Step 2: Defining a forward simulation as a synthetic ground truth</a><a id="Step-2:-Defining-a-forward-simulation-as-a-synthetic-ground-truth-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2:-Defining-a-forward-simulation-as-a-synthetic-ground-truth" title="Permalink"></a></h3><p>The next step is to generate a synthetic dataset using a forward simulation. This will generate a dataset with the ice thickness and surface velocities for each glacier at each time step. The dataset will be used to train the machine learning model. We define a synthetic law to generate the synthetic dataset. For this, we use some tabular data from Cuffey and Paterson (2010). The REPL shows that it maps the long term air temperature <code>T</code> to the creep coefficient <code>A</code>.</p><pre><code class="language-julia hljs">A_law = CuffeyPaterson()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(:T,) -&gt; Array{Float64, 0}   (⟳  )
</code></pre><p>The model is initialized using the <code>Model</code> constructor:</p><pre><code class="language-julia hljs">model = Model(
    iceflow = SIA2Dmodel(params; A=A_law),
    mass_balance = TImodel1(params; DDF=6.0/1000.0, acc_factor=1.2/1000.0),
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">**** Model ****

SIA2D iceflow equation  = ∇(<span class="sgr32">D</span> ∇S)  with <span class="sgr32">D</span> = <span class="sgr31">U</span> H̄
  and <span class="sgr31">U</span> = (<span class="sgr35">C</span> (ρg)^<span class="sgr33">n</span> + <span class="sgr36">Γ</span> H̄) H̄^<span class="sgr33">n</span> ∇S^(<span class="sgr33">n</span>-1)
<span class="sgr36">      Γ</span> = 2<span class="sgr34">A</span> (ρg)^<span class="sgr33">n</span> /(<span class="sgr33">n</span>+2)
<span class="sgr34">      A: </span>(:T,) -&gt; Array{Float64, 0}   (⟳  )
<span class="sgr35">      C: </span>ConstantLaw -&gt; Array{Float64, 0}
<span class="sgr33">      n: </span>ConstantLaw -&gt; Array{Float64, 0}
  where
      T =&gt; long_term_temperature

Temperature index mass balance model TImodel1
   DDF = 0.006
   acc_factor = 0.0012
No learnable components
***************</code></pre><p>We define the time snapshots for transient inversion, i.e. the time steps at which we want to save the results, which will be used to compute the adjoint in reverse mode.</p><pre><code class="language-julia hljs">tstops = collect(2010:δt:2015)

prediction = Prediction(model, glaciers, params)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Prediction{Sleipnir.ModelCache{SIA2DCache{Float64, Int64, ScalarCacheNoVJP, ScalarCacheNoVJP, ScalarCacheNoVJP, Array{Float64, 0}, Array{Float64, 0}, ScalarCacheNoVJP, ScalarCacheNoVJP}, Nothing}}(Sleipnir.Model{SIA2Dmodel{Float64, Law{ScalarCacheNoVJP, Sleipnir.GenInputsAndApply{@NamedTuple{T::iTemp}, Huginn.var&quot;#27#29&quot;{Polynomials.Polynomial{Float64, :x}}}, Sleipnir.GenInputsAndApply{@NamedTuple{T::iTemp}, typeof(Sleipnir.emptyVJPWithInputs)}, Sleipnir.GenInputsAndApply{@NamedTuple{T::iTemp}, typeof(Sleipnir.emptyVJPWithInputs)}, Huginn.var&quot;#28#30&quot;, Nothing, Sleipnir.GenInputsAndApply{@NamedTuple{T::iTemp}, typeof(Sleipnir.emptyPrepVJPWithInputs)}, DIVJP}, ConstantLaw{ScalarCacheNoVJP, Huginn.var&quot;#9#10&quot;}, ConstantLaw{ScalarCacheNoVJP, Huginn.var&quot;#11#12&quot;}, NullLaw, NullLaw}, TImodel1{Float64}, Nothing}(SIA2D iceflow equation  = ∇(<span class="sgr32">D</span> ∇S)  with <span class="sgr32">D</span> = <span class="sgr31">U</span> H̄
  and <span class="sgr31">U</span> = (<span class="sgr35">C</span> (ρg)^<span class="sgr33">n</span> + <span class="sgr36">Γ</span> H̄) H̄^<span class="sgr33">n</span> ∇S^(<span class="sgr33">n</span>-1)
<span class="sgr36">      Γ</span> = 2<span class="sgr34">A</span> (ρg)^<span class="sgr33">n</span> /(<span class="sgr33">n</span>+2)
<span class="sgr34">      A: </span>(:T,) -&gt; Array{Float64, 0}   (⟳  )
<span class="sgr35">      C: </span>ConstantLaw -&gt; Array{Float64, 0}
<span class="sgr33">      n: </span>ConstantLaw -&gt; Array{Float64, 0}
  where
      T =&gt; long_term_temperature
, Temperature index mass balance model TImodel1
   DDF = 0.006
   acc_factor = 0.0012, nothing), nothing, 4-element Vector{AbstractGlacier} distributed over regions 07 (x1), 11 (x3)
RGI60-11.03638 RGI60-11.01450 RGI60-11.02346 RGI60-07.00065
, Sleipnir.Parameters{PhysicalParameters{Float64}, SimulationParameters{Int64, Float64, MeanDateVelocityMapping}, Hyperparameters{Float64, Int64}, SolverParameters{Float64, Int64}, UDEparameters{ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP}}, InversionParameters{Float64}}(PhysicalParameters{Float64}(900.0, 9.81, 1.0e-10, 1.0, 8.0e-17, 8.0e-21, 8.0e-17, 8.5e-20, 1.0, -25.0, 5.0e-18), SimulationParameters{Int64, Float64, MeanDateVelocityMapping}(false, true, true, true, 1.0, false, false, (2010.0, 2015.0), 0.08333333333333333, true, 4, &quot;/home/runner/work/ODINN.jl/ODINN.jl/demos&quot;, false, Dict(&quot;RGI60-11.00897&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.00/RGI60-11.00897&quot;, &quot;RGI60-08.00213&quot; =&gt; &quot;per_glacier/RGI60-08/RGI60-08.00/RGI60-08.00213&quot;, &quot;RGI60-08.00147&quot; =&gt; &quot;per_glacier/RGI60-08/RGI60-08.00/RGI60-08.00147&quot;, &quot;RGI60-11.01270&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.01/RGI60-11.01270&quot;, &quot;RGI60-11.03646&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.03/RGI60-11.03646&quot;, &quot;RGI60-11.03232&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.03/RGI60-11.03232&quot;, &quot;RGI60-01.22174&quot; =&gt; &quot;per_glacier/RGI60-01/RGI60-01.22/RGI60-01.22174&quot;, &quot;RGI60-07.00274&quot; =&gt; &quot;per_glacier/RGI60-07/RGI60-07.00/RGI60-07.00274&quot;, &quot;RGI60-03.04207&quot; =&gt; &quot;per_glacier/RGI60-03/RGI60-03.04/RGI60-03.04207&quot;, &quot;RGI60-04.04351&quot; =&gt; &quot;per_glacier/RGI60-04/RGI60-04.04/RGI60-04.04351&quot;…), &quot;Farinotti19&quot;, MeanDateVelocityMapping(:nearest), 4), Hyperparameters{Float64, Int64}(1, 1, Float64[], Any[Optimisers.Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), Optim.LBFGS{Nothing, LineSearches.InitialStatic{Float64}, LineSearches.BackTracking{Float64, Int64}, Returns{Nothing}}(10, LineSearches.InitialStatic{Float64}
  alpha: Float64 1.0
  scaled: Bool false
, LineSearches.BackTracking{Float64, Int64}
  c_1: Float64 0.0001
  ρ_hi: Float64 0.5
  ρ_lo: Float64 0.1
  iterations: Int64 5
  order: Int64 3
  maxstep: Float64 Inf
  cache: Nothing nothing
, nothing, Returns{Nothing}(nothing), Optim.Flat(), true)], 0.0, [15, 10], 4), SolverParameters{Float64, Int64}(OrdinaryDiffEqLowStorageRK.RDPK3Sp35{typeof(OrdinaryDiffEqCore.trivial_limiter!), typeof(OrdinaryDiffEqCore.trivial_limiter!), Static.False}(OrdinaryDiffEqCore.trivial_limiter!, OrdinaryDiffEqCore.trivial_limiter!, static(false)), 1.0e-12, 0.08333333333333333, Float64[], false, true, 10, 100000), UDEparameters{ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP}}(SciMLSensitivity.GaussAdjoint{0, true, Val{:central}, SciMLSensitivity.EnzymeVJP}(SciMLSensitivity.EnzymeVJP(0), false), SciMLBase.NoAD(), ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP}(DiscreteVJP{ADTypes.AutoMooncake{Nothing}}(ADTypes.AutoMooncake()), OrdinaryDiffEqLowStorageRK.RDPK3Sp35{typeof(OrdinaryDiffEqCore.trivial_limiter!), typeof(OrdinaryDiffEqCore.trivial_limiter!), Static.False}(OrdinaryDiffEqCore.trivial_limiter!, OrdinaryDiffEqCore.trivial_limiter!, static(false)), 1.0e-8, 1.0e-8, 0.08333333333333333, :Linear, 200, EnzymeVJP()), &quot;AD+AD&quot;, MultiLoss{Tuple{LossH{L2Sum{Int64}}}, Vector{Float64}}((LossH{L2Sum{Int64}}(L2Sum{Int64}(3)),), [1.0]), :A, :identity), InversionParameters{Float64}([1.0], [0.0], [Inf], [1, 1], 0.001, 0.001, Optim.BFGS{LineSearches.InitialStatic{Float64}, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}, Nothing, Nothing, Optim.Flat}(LineSearches.InitialStatic{Float64}
  alpha: Float64 1.0
  scaled: Bool false
, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}
  delta: Float64 0.1
  sigma: Float64 0.9
  alphamax: Float64 Inf
  rho: Float64 5.0
  epsilon: Float64 1.0e-6
  gamma: Float64 0.66
  linesearchmax: Int64 50
  psi3: Float64 0.1
  display: Int64 0
  mayterminate: Base.RefValue{Bool}
  cache: Nothing nothing
  check_flatness: Bool false
, nothing, nothing, Optim.Flat()))), Sleipnir.Results[])</code></pre><p>We generate the synthetic dataset using the forward simulation. This will generate a dataset with the ice thickness and surface velocities for each glacier at each time step. The dataset will be used to train the machine learning model. This will  run under the hood a <code>Prediction</code> using <code>Huginn.jl</code>.</p><pre><code class="language-julia hljs">glaciers = generate_ground_truth(glaciers, params, model, tstops)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Glacier2D} distributed over regions 07 (x1), 11 (x3)
RGI60-11.03638 RGI60-11.01450 RGI60-11.02346 RGI60-07.00065
</code></pre><p>The results of this simulation are stored in the <code>thicknessData</code> field of each glacier.</p><h3 id="Step-3:-Model-specification-to-perform-a-functional-inversion"><a class="docs-heading-anchor" href="#Step-3:-Model-specification-to-perform-a-functional-inversion">Step 3: Model specification to perform a functional inversion</a><a id="Step-3:-Model-specification-to-perform-a-functional-inversion-1"></a><a class="docs-heading-anchor-permalink" href="#Step-3:-Model-specification-to-perform-a-functional-inversion" title="Permalink"></a></h3><p>After this forward simulation, we define a new iceflow model to be ready for the inversions. The first step is to define a simple neural network that takes as input a scalar and returns a scalar.</p><pre><code class="language-julia hljs">nn_model = NeuralNetwork(params)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">--- NeuralNetwork ---
    architecture:
      Chain(
          layer_1 = Dense(1 =&gt; 3, #99),                 # 6 parameters
          layer_2 = Dense(3 =&gt; 10, #100),               # 40 parameters
          layer_3 = Dense(10 =&gt; 3, #101),               # 33 parameters
          layer_4 = Dense(3 =&gt; 1, σ),                   # 4 parameters
      )         # Total: 83 parameters,
                #        plus 0 states.
    θ: ComponentVector of length 83</code></pre><p>Then we define a law that uses this neural network to map the long term air temperature <code>T</code> to the creep coefficient <code>A</code>. ODINN comes with a set of already defined laws. Only a few of them support functional inversion as the computation of the gradient needs to be carefully handled. More information about these laws can be found in the laws tutorial.</p><pre><code class="language-julia hljs">A_law = LawA(nn_model, params)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(:T,) -&gt; Array{Float64, 0}   (↧@start  custom VJP  ✅ precomputed)
</code></pre><p>Then we define an iceflow and ODINN tells us how the law is used in the iceflow equation.</p><pre><code class="language-julia hljs">iceflow = SIA2Dmodel(params; A=A_law)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">SIA2D iceflow equation  = ∇(<span class="sgr32">D</span> ∇S)  with <span class="sgr32">D</span> = <span class="sgr31">U</span> H̄
  and <span class="sgr31">U</span> = (<span class="sgr35">C</span> (ρg)^<span class="sgr33">n</span> + <span class="sgr36">Γ</span> H̄) H̄^<span class="sgr33">n</span> ∇S^(<span class="sgr33">n</span>-1)
<span class="sgr36">      Γ</span> = 2<span class="sgr34">A</span> (ρg)^<span class="sgr33">n</span> /(<span class="sgr33">n</span>+2)
<span class="sgr34">      A: </span>(:T,) -&gt; Array{Float64, 0}   (↧@start  custom VJP  ✅ precomputed)
<span class="sgr35">      C: </span>ConstantLaw -&gt; Array{Float64, 0}
<span class="sgr33">      n: </span>ConstantLaw -&gt; Array{Float64, 0}
  where
      T =&gt; long_term_temperature
</code></pre><p>Finally we define the model which needs to know the iceflow and mass balance models, and in comparison to Huginn, there is a third argument <code>regressors</code>. This <code>regressors</code> argument tells how each regressor relates into the SIA. Although we already defined this in the iceflow model, this definition is mandatory for technical reasons. This argument will probably disappear in the future once the code becomes more mature. It must match how the laws are defined in the iceflow model.</p><pre><code class="language-julia hljs">model = Model(
    iceflow = iceflow,
    mass_balance = TImodel1(params; DDF=6.0/1000.0, acc_factor=1.2/1000.0),
    regressors = (; A=nn_model)
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">**** Model ****

SIA2D iceflow equation  = ∇(<span class="sgr32">D</span> ∇S)  with <span class="sgr32">D</span> = <span class="sgr31">U</span> H̄
  and <span class="sgr31">U</span> = (<span class="sgr35">C</span> (ρg)^<span class="sgr33">n</span> + <span class="sgr36">Γ</span> H̄) H̄^<span class="sgr33">n</span> ∇S^(<span class="sgr33">n</span>-1)
<span class="sgr36">      Γ</span> = 2<span class="sgr34">A</span> (ρg)^<span class="sgr33">n</span> /(<span class="sgr33">n</span>+2)
<span class="sgr34">      A: </span>(:T,) -&gt; Array{Float64, 0}   (↧@start  custom VJP  ✅ precomputed)
<span class="sgr35">      C: </span>ConstantLaw -&gt; Array{Float64, 0}
<span class="sgr33">      n: </span>ConstantLaw -&gt; Array{Float64, 0}
  where
      T =&gt; long_term_temperature

Temperature index mass balance model TImodel1
   DDF = 0.006
   acc_factor = 0.0012
Learnable components
  A: --- NeuralNetwork ---
    architecture:
      Chain(
          layer_1 = Dense(1 =&gt; 3, #99),                 # 6 parameters
          layer_2 = Dense(3 =&gt; 10, #100),               # 40 parameters
          layer_3 = Dense(10 =&gt; 3, #101),               # 33 parameters
          layer_4 = Dense(3 =&gt; 1, σ),                   # 4 parameters
      )         # Total: 83 parameters,
                #        plus 0 states.
    θ: ComponentVector of length 83

***************</code></pre><h3 id="Step-4:-Train-a-Universal-Differential-Equation-via-a-functional-inversion"><a class="docs-heading-anchor" href="#Step-4:-Train-a-Universal-Differential-Equation-via-a-functional-inversion">Step 4: Train a Universal Differential Equation via a functional inversion</a><a id="Step-4:-Train-a-Universal-Differential-Equation-via-a-functional-inversion-1"></a><a class="docs-heading-anchor-permalink" href="#Step-4:-Train-a-Universal-Differential-Equation-via-a-functional-inversion" title="Permalink"></a></h3><p>The next step is to specify the type of simulation we want to perform. In this case, we will use a <code>Inversion</code> simulation, which will use the synthetic dataset generated in the previous step to train a Universal Differential Equation (UDE) model.</p><pre><code class="language-julia hljs">functional_inversion = Inversion(model, glaciers, params)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Inversion{Sleipnir.Model{SIA2Dmodel{Float64, Law{ScalarCache, Sleipnir.GenInputsAndApply{@NamedTuple{T::iTemp}, ODINN.var&quot;#232#237&quot;{LuxCore.StatefulLuxLayerImpl.StatefulLuxLayer{Val{true}, Lux.Chain{@NamedTuple{layer_1::Lux.Dense{ODINN.var&quot;#99#103&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{ODINN.var&quot;#100#104&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Lux.Dense{ODINN.var&quot;#101#105&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Lux.Dense{typeof(NNlib.σ), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}, Float64, Float64}}, Sleipnir.GenInputsAndApply{@NamedTuple{T::iTemp}, typeof(Sleipnir.emptyVJPWithInputs)}, Sleipnir.GenInputsAndApply{@NamedTuple{T::iTemp}, typeof(Sleipnir.emptyVJPWithInputs)}, ODINN.var&quot;#236#241&quot;, Int64, Sleipnir.GenInputsAndApply{@NamedTuple{T::iTemp}, ODINN.var&quot;#234#239&quot;{ODINN.var&quot;#232#237&quot;{LuxCore.StatefulLuxLayerImpl.StatefulLuxLayer{Val{true}, Lux.Chain{@NamedTuple{layer_1::Lux.Dense{ODINN.var&quot;#99#103&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{ODINN.var&quot;#100#104&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Lux.Dense{ODINN.var&quot;#101#105&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Lux.Dense{typeof(NNlib.σ), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}, Float64, Float64}}}, CustomVJP}, ConstantLaw{ScalarCacheNoVJP, Huginn.var&quot;#9#10&quot;}, ConstantLaw{ScalarCacheNoVJP, Huginn.var&quot;#11#12&quot;}, NullLaw, NullLaw}, TImodel1{Float64}, ODINN.MachineLearning{NeuralNetwork{Lux.Chain{@NamedTuple{layer_1::Lux.Dense{ODINN.var&quot;#99#103&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{ODINN.var&quot;#100#104&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Lux.Dense{ODINN.var&quot;#101#105&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Lux.Dense{typeof(NNlib.σ), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, ComponentArrays.ComponentVector{Float64, Vector{Float64}, Tuple{ComponentArrays.Axis{(θ = ViewAxis(1:83, Axis(layer_1 = ViewAxis(1:6, Axis(weight = ViewAxis(1:3, ShapedAxis((3, 1))), bias = ViewAxis(4:6, Shaped1DAxis((3,))))), layer_2 = ViewAxis(7:46, Axis(weight = ViewAxis(1:30, ShapedAxis((10, 3))), bias = ViewAxis(31:40, Shaped1DAxis((10,))))), layer_3 = ViewAxis(47:79, Axis(weight = ViewAxis(1:30, ShapedAxis((3, 10))), bias = ViewAxis(31:33, Shaped1DAxis((3,))))), layer_4 = ViewAxis(80:83, Axis(weight = ViewAxis(1:3, ShapedAxis((1, 3))), bias = ViewAxis(4:4, Shaped1DAxis((1,))))))),)}}}, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}, ODINN.emptyTrainableModel, ODINN.emptyTrainableModel, ODINN.emptyTrainableModel, ODINN.emptyTrainableModel, ODINN.emptyIC, SIA2D_A_target, ComponentArrays.ComponentVector{Float64, Vector{Float64}, Tuple{ComponentArrays.Axis{(A = ViewAxis(1:83, Axis(layer_1 = ViewAxis(1:6, Axis(weight = ViewAxis(1:3, ShapedAxis((3, 1))), bias = ViewAxis(4:6, Shaped1DAxis((3,))))), layer_2 = ViewAxis(7:46, Axis(weight = ViewAxis(1:30, ShapedAxis((10, 3))), bias = ViewAxis(31:40, Shaped1DAxis((10,))))), layer_3 = ViewAxis(47:79, Axis(weight = ViewAxis(1:30, ShapedAxis((3, 10))), bias = ViewAxis(31:33, Shaped1DAxis((3,))))), layer_4 = ViewAxis(80:83, Axis(weight = ViewAxis(1:3, ShapedAxis((1, 3))), bias = ViewAxis(4:4, Shaped1DAxis((1,))))))),)}}}}}, Sleipnir.ModelCache{SIA2DCache{Float64, Int64, ScalarCache, ScalarCacheNoVJP, ScalarCacheNoVJP, Array{Float64, 0}, Array{Float64, 0}, ScalarCacheNoVJP, ScalarCacheNoVJP}, Nothing}, Glacier2D{Float64, Int64, Climate2D{Rasters.RasterStack{(:prcp, :temp, :gradient), @NamedTuple{prcp::Float64, temp::Float64, gradient::Float64}, 1, @NamedTuple{prcp::Vector{Float64}, temp::Vector{Float64}, gradient::Vector{Float64}}, Tuple{DimensionalData.Dimensions.Ti{DimensionalData.Dimensions.Lookups.Sampled{Dates.DateTime, Vector{Dates.DateTime}, DimensionalData.Dimensions.Lookups.ForwardOrdered, DimensionalData.Dimensions.Lookups.Irregular{Tuple{Nothing, Nothing}}, DimensionalData.Dimensions.Lookups.Points, DimensionalData.Dimensions.Lookups.Metadata{Rasters.NCDsource, Dict{String, Any}}}}}, Tuple{}, @NamedTuple{prcp::Tuple{DimensionalData.Dimensions.Ti{Colon}}, temp::Tuple{DimensionalData.Dimensions.Ti{Colon}}, gradient::Tuple{DimensionalData.Dimensions.Ti{Colon}}}, DimensionalData.Dimensions.Lookups.Metadata{Rasters.NCDsource, Dict{String, Any}}, @NamedTuple{prcp::DimensionalData.Dimensions.Lookups.Metadata{Rasters.NCDsource, Dict{String, Any}}, temp::DimensionalData.Dimensions.Lookups.Metadata{Rasters.NCDsource, Dict{String, Any}}, gradient::DimensionalData.Dimensions.Lookups.Metadata{Rasters.NCDsource, Dict{String, Any}}}, Nothing}, Rasters.RasterStack{(:prcp, :temp, :gradient), @NamedTuple{prcp::Float64, temp::Float64, gradient::Float64}, 1, @NamedTuple{prcp::Vector{Float64}, temp::Vector{Float64}, gradient::Vector{Float64}}, Tuple{DimensionalData.Dimensions.Ti{DimensionalData.Dimensions.Lookups.Sampled{Dates.DateTime, Vector{Dates.DateTime}, DimensionalData.Dimensions.Lookups.ForwardOrdered, DimensionalData.Dimensions.Lookups.Irregular{Tuple{Nothing, Nothing}}, DimensionalData.Dimensions.Lookups.Points, DimensionalData.Dimensions.Lookups.Metadata{Rasters.NCDsource, Dict{String, Any}}}}}, Tuple{}, @NamedTuple{prcp::Tuple{DimensionalData.Dimensions.Ti{Colon}}, temp::Tuple{DimensionalData.Dimensions.Ti{Colon}}, gradient::Tuple{DimensionalData.Dimensions.Ti{Colon}}}, DimensionalData.Dimensions.Lookups.Metadata{Rasters.NCDsource, Dict{String, Any}}, @NamedTuple{prcp::DimensionalData.Dimensions.Lookups.Metadata{Rasters.NCDsource, Dict{String, Any}}, temp::DimensionalData.Dimensions.Lookups.Metadata{Rasters.NCDsource, Dict{String, Any}}, gradient::DimensionalData.Dimensions.Lookups.Metadata{Rasters.NCDsource, Dict{String, Any}}}, Nothing}, Sleipnir.ClimateStep{Float64}, Climate2Dstep{Float64}, Float64}, ThicknessData{Float64}, SurfaceVelocityData{Float64}}, Results{Sleipnir.Results{Float64, Int64}, TrainingStats{Float64, Int64}}}(Sleipnir.Model{SIA2Dmodel{Float64, Law{ScalarCache, Sleipnir.GenInputsAndApply{@NamedTuple{T::iTemp}, ODINN.var&quot;#232#237&quot;{LuxCore.StatefulLuxLayerImpl.StatefulLuxLayer{Val{true}, Lux.Chain{@NamedTuple{layer_1::Lux.Dense{ODINN.var&quot;#99#103&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{ODINN.var&quot;#100#104&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Lux.Dense{ODINN.var&quot;#101#105&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Lux.Dense{typeof(NNlib.σ), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}, Float64, Float64}}, Sleipnir.GenInputsAndApply{@NamedTuple{T::iTemp}, typeof(Sleipnir.emptyVJPWithInputs)}, Sleipnir.GenInputsAndApply{@NamedTuple{T::iTemp}, typeof(Sleipnir.emptyVJPWithInputs)}, ODINN.var&quot;#236#241&quot;, Int64, Sleipnir.GenInputsAndApply{@NamedTuple{T::iTemp}, ODINN.var&quot;#234#239&quot;{ODINN.var&quot;#232#237&quot;{LuxCore.StatefulLuxLayerImpl.StatefulLuxLayer{Val{true}, Lux.Chain{@NamedTuple{layer_1::Lux.Dense{ODINN.var&quot;#99#103&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{ODINN.var&quot;#100#104&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Lux.Dense{ODINN.var&quot;#101#105&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Lux.Dense{typeof(NNlib.σ), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}, Float64, Float64}}}, CustomVJP}, ConstantLaw{ScalarCacheNoVJP, Huginn.var&quot;#9#10&quot;}, ConstantLaw{ScalarCacheNoVJP, Huginn.var&quot;#11#12&quot;}, NullLaw, NullLaw}, TImodel1{Float64}, ODINN.MachineLearning{NeuralNetwork{Lux.Chain{@NamedTuple{layer_1::Lux.Dense{ODINN.var&quot;#99#103&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{ODINN.var&quot;#100#104&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Lux.Dense{ODINN.var&quot;#101#105&quot;, Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Lux.Dense{typeof(NNlib.σ), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, ComponentArrays.ComponentVector{Float64, Vector{Float64}, Tuple{ComponentArrays.Axis{(θ = ViewAxis(1:83, Axis(layer_1 = ViewAxis(1:6, Axis(weight = ViewAxis(1:3, ShapedAxis((3, 1))), bias = ViewAxis(4:6, Shaped1DAxis((3,))))), layer_2 = ViewAxis(7:46, Axis(weight = ViewAxis(1:30, ShapedAxis((10, 3))), bias = ViewAxis(31:40, Shaped1DAxis((10,))))), layer_3 = ViewAxis(47:79, Axis(weight = ViewAxis(1:30, ShapedAxis((3, 10))), bias = ViewAxis(31:33, Shaped1DAxis((3,))))), layer_4 = ViewAxis(80:83, Axis(weight = ViewAxis(1:3, ShapedAxis((1, 3))), bias = ViewAxis(4:4, Shaped1DAxis((1,))))))),)}}}, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}, ODINN.emptyTrainableModel, ODINN.emptyTrainableModel, ODINN.emptyTrainableModel, ODINN.emptyTrainableModel, ODINN.emptyIC, SIA2D_A_target, ComponentArrays.ComponentVector{Float64, Vector{Float64}, Tuple{ComponentArrays.Axis{(A = ViewAxis(1:83, Axis(layer_1 = ViewAxis(1:6, Axis(weight = ViewAxis(1:3, ShapedAxis((3, 1))), bias = ViewAxis(4:6, Shaped1DAxis((3,))))), layer_2 = ViewAxis(7:46, Axis(weight = ViewAxis(1:30, ShapedAxis((10, 3))), bias = ViewAxis(31:40, Shaped1DAxis((10,))))), layer_3 = ViewAxis(47:79, Axis(weight = ViewAxis(1:30, ShapedAxis((3, 10))), bias = ViewAxis(31:33, Shaped1DAxis((3,))))), layer_4 = ViewAxis(80:83, Axis(weight = ViewAxis(1:3, ShapedAxis((1, 3))), bias = ViewAxis(4:4, Shaped1DAxis((1,))))))),)}}}}}(SIA2D iceflow equation  = ∇(<span class="sgr32">D</span> ∇S)  with <span class="sgr32">D</span> = <span class="sgr31">U</span> H̄
  and <span class="sgr31">U</span> = (<span class="sgr35">C</span> (ρg)^<span class="sgr33">n</span> + <span class="sgr36">Γ</span> H̄) H̄^<span class="sgr33">n</span> ∇S^(<span class="sgr33">n</span>-1)
<span class="sgr36">      Γ</span> = 2<span class="sgr34">A</span> (ρg)^<span class="sgr33">n</span> /(<span class="sgr33">n</span>+2)
<span class="sgr34">      A: </span>(:T,) -&gt; Array{Float64, 0}   (↧@start  custom VJP  ✅ precomputed)
<span class="sgr35">      C: </span>ConstantLaw -&gt; Array{Float64, 0}
<span class="sgr33">      n: </span>ConstantLaw -&gt; Array{Float64, 0}
  where
      T =&gt; long_term_temperature
, Temperature index mass balance model TImodel1
   DDF = 0.006
   acc_factor = 0.0012,   A: --- NeuralNetwork ---
    architecture:
      Chain(
          layer_1 = Dense(1 =&gt; 3, #99),                 # 6 parameters
          layer_2 = Dense(3 =&gt; 10, #100),               # 40 parameters
          layer_3 = Dense(10 =&gt; 3, #101),               # 33 parameters
          layer_4 = Dense(3 =&gt; 1, σ),                   # 4 parameters
      )         # Total: 83 parameters,
                #        plus 0 states.
    θ: ComponentVector of length 83
), nothing, 4-element Vector{Glacier2D} distributed over regions 07 (x1), 11 (x3)
RGI60-11.03638 RGI60-11.01450 RGI60-11.02346 RGI60-07.00065
, Sleipnir.Parameters{PhysicalParameters{Float64}, SimulationParameters{Int64, Float64, MeanDateVelocityMapping}, Hyperparameters{Float64, Int64}, SolverParameters{Float64, Int64}, UDEparameters{ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP}}, InversionParameters{Float64}}(PhysicalParameters{Float64}(900.0, 9.81, 1.0e-10, 1.0, 8.0e-17, 8.0e-21, 8.0e-17, 8.5e-20, 1.0, -25.0, 5.0e-18), SimulationParameters{Int64, Float64, MeanDateVelocityMapping}(false, true, true, true, 1.0, false, false, (2010.0, 2015.0), 0.08333333333333333, true, 4, &quot;/home/runner/work/ODINN.jl/ODINN.jl/demos&quot;, false, Dict(&quot;RGI60-11.00897&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.00/RGI60-11.00897&quot;, &quot;RGI60-08.00213&quot; =&gt; &quot;per_glacier/RGI60-08/RGI60-08.00/RGI60-08.00213&quot;, &quot;RGI60-08.00147&quot; =&gt; &quot;per_glacier/RGI60-08/RGI60-08.00/RGI60-08.00147&quot;, &quot;RGI60-11.01270&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.01/RGI60-11.01270&quot;, &quot;RGI60-11.03646&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.03/RGI60-11.03646&quot;, &quot;RGI60-11.03232&quot; =&gt; &quot;per_glacier/RGI60-11/RGI60-11.03/RGI60-11.03232&quot;, &quot;RGI60-01.22174&quot; =&gt; &quot;per_glacier/RGI60-01/RGI60-01.22/RGI60-01.22174&quot;, &quot;RGI60-07.00274&quot; =&gt; &quot;per_glacier/RGI60-07/RGI60-07.00/RGI60-07.00274&quot;, &quot;RGI60-03.04207&quot; =&gt; &quot;per_glacier/RGI60-03/RGI60-03.04/RGI60-03.04207&quot;, &quot;RGI60-04.04351&quot; =&gt; &quot;per_glacier/RGI60-04/RGI60-04.04/RGI60-04.04351&quot;…), &quot;Farinotti19&quot;, MeanDateVelocityMapping(:nearest), 4), Hyperparameters{Float64, Int64}(1, 1, Float64[], Any[Optimisers.Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), Optim.LBFGS{Nothing, LineSearches.InitialStatic{Float64}, LineSearches.BackTracking{Float64, Int64}, Returns{Nothing}}(10, LineSearches.InitialStatic{Float64}
  alpha: Float64 1.0
  scaled: Bool false
, LineSearches.BackTracking{Float64, Int64}
  c_1: Float64 0.0001
  ρ_hi: Float64 0.5
  ρ_lo: Float64 0.1
  iterations: Int64 5
  order: Int64 3
  maxstep: Float64 Inf
  cache: Nothing nothing
, nothing, Returns{Nothing}(nothing), Optim.Flat(), true)], 0.0, [15, 10], 4), SolverParameters{Float64, Int64}(OrdinaryDiffEqLowStorageRK.RDPK3Sp35{typeof(OrdinaryDiffEqCore.trivial_limiter!), typeof(OrdinaryDiffEqCore.trivial_limiter!), Static.False}(OrdinaryDiffEqCore.trivial_limiter!, OrdinaryDiffEqCore.trivial_limiter!, static(false)), 1.0e-12, 0.08333333333333333, Float64[], false, true, 10, 100000), UDEparameters{ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP}}(SciMLSensitivity.GaussAdjoint{0, true, Val{:central}, SciMLSensitivity.EnzymeVJP}(SciMLSensitivity.EnzymeVJP(0), false), SciMLBase.NoAD(), ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP}(DiscreteVJP{ADTypes.AutoMooncake{Nothing}}(ADTypes.AutoMooncake()), OrdinaryDiffEqLowStorageRK.RDPK3Sp35{typeof(OrdinaryDiffEqCore.trivial_limiter!), typeof(OrdinaryDiffEqCore.trivial_limiter!), Static.False}(OrdinaryDiffEqCore.trivial_limiter!, OrdinaryDiffEqCore.trivial_limiter!, static(false)), 1.0e-8, 1.0e-8, 0.08333333333333333, :Linear, 200, EnzymeVJP()), &quot;AD+AD&quot;, MultiLoss{Tuple{LossH{L2Sum{Int64}}}, Vector{Float64}}((LossH{L2Sum{Int64}}(L2Sum{Int64}(3)),), [1.0]), :A, :identity), InversionParameters{Float64}([1.0], [0.0], [Inf], [1, 1], 0.001, 0.001, Optim.BFGS{LineSearches.InitialStatic{Float64}, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}, Nothing, Nothing, Optim.Flat}(LineSearches.InitialStatic{Float64}
  alpha: Float64 1.0
  scaled: Bool false
, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}
  delta: Float64 0.1
  sigma: Float64 0.9
  alphamax: Float64 Inf
  rho: Float64 5.0
  epsilon: Float64 1.0e-6
  gamma: Float64 0.66
  linesearchmax: Int64 50
  psi3: Float64 0.1
  display: Int64 0
  mayterminate: Base.RefValue{Bool}
  cache: Nothing nothing
  check_flatness: Bool false
, nothing, nothing, Optim.Flat()))), Results{Sleipnir.Results{Float64, Int64}, TrainingStats{Float64, Int64}}(Sleipnir.Results{Float64, Int64}[], TrainingStats{Float64, Int64}(nothing, Float64[], 0, nothing, ComponentArrays.ComponentVector[], ComponentArrays.ComponentVector[], nothing, Dates.DateTime(&quot;0000-01-01T00:00:00&quot;))))</code></pre><p>And finally, we just run the simulation. This will run the adjoint method to compute the gradients and then use the ADAM optimizer to train the UDE model.</p><pre><code class="language-julia hljs">run!(functional_inversion)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Training UDE...

[ Info: Training with ADAM optimizer
[ Info: Training with custom ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP} method
Iteration: [    1 /    25]     Loss:7.90137e+01
Iteration: [    2 /    25]     Loss:6.52403e+01     Improvement: -17.43 %
Iteration: [    3 /    25]     Loss:5.40509e+01     Improvement: -17.15 %
Iteration: [    4 /    25]     Loss:4.57279e+01     Improvement: -15.40 %
Iteration: [    5 /    25]     Loss:3.89663e+01     Improvement: -14.79 %
Iteration: [    6 /    25]     Loss:3.35554e+01     Improvement: -13.89 %
Iteration: [    7 /    25]     Loss:2.91507e+01     Improvement: -13.13 %
Iteration: [    8 /    25]     Loss:2.55161e+01     Improvement: -12.47 %
Iteration: [    9 /    25]     Loss:2.21683e+01     Improvement: -13.12 %
Iteration: [   10 /    25]     Loss:1.99518e+01     Improvement: -10.00 %
Iteration: [   11 /    25]     Loss:1.75260e+01     Improvement: -12.16 %
Iteration: [   12 /    25]     Loss:1.59671e+01     Improvement: -8.89 %
Iteration: [   13 /    25]     Loss:1.44823e+01     Improvement: -9.30 %
Iteration: [   14 /    25]     Loss:1.31806e+01     Improvement: -8.99 %
Iteration: [   15 /    25]     Loss:1.20103e+01     Improvement: -8.88 %
Iteration: [   16 /    25]     Loss:1.20103e+01     Improvement: 0.00 %
[ Info: Training with BFGS optimizer
[ Info: Training with custom ContinuousAdjoint{Float64, Int64, DiscreteVJP{ADTypes.AutoMooncake{Nothing}}, EnzymeVJP} method
Iteration: [   17 /    25]     Loss:1.20103e+01     Improvement: 0.00 %
Iteration: [   18 /    25]     Loss:1.08576e+01     Improvement: -9.60 %</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../forward_simulation/">« Forward simulation</a><a class="docs-footer-nextpage" href="../laws/">Laws »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.0 on <span class="colophon-date" title="Wednesday 19 November 2025 19:08">Wednesday 19 November 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
